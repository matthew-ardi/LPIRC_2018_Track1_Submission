<!DOCTYPE html><html><head><title></title><meta http-equiv="content-type" content="text/html; charset=utf-8" /><meta name="author" content="Xin Liu" /><meta name="lastsavedby" content="Jingchi Zhang" /><meta name="datecontentcreated" content="2018-04-23T22:11:00Z" /><meta name="datelastsaved" content="2018-04-25T20:43:00Z" /><meta name="application" content="Microsoft Office Word" /></head><body><div><p style="text-align:center;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:14pt;">LPIRC CVPR 2018 Track 2 Description</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span>&#xa0;</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:12pt;font-weight: bold;">Description:</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">Track 2 of LPIRC CVPR 2018 is a public competition for accurate and low power consumption image classifiers. Participants of track 2 will be evaluated based on both accuracy and power usage. Nowadays, cameras have become available in many embedded and mobile systems, including smartphones, wearable devices and aerial robots. It is desirable to have the capability of detecting objects in the images by computers. At the meantime, energy is limited in mobile systems so energy conservation is important.</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">In order to measure the energy consumption, we use jetson TX2 as a unified platform. We would measure the power consumption of your model on your own TX2. This track encourages system-level improvements (e.g., better cache performance or voltage scaling). Track 2 uses Caffe2 because of its high performance and mobile deployment, and flexibility for future applications.</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span>&#xa0;</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:12pt;font-weight: bold;">Requirement:</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">There are two main requirements for Track 2:</span></p><p style="text-align:justify;margin-left:18pt;text-indent:-18pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">1.</span><span>&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; </span><span style="font-family:Times New Roman;font-size:10.5pt;">Participants must use Caffe2 (</span><a href="https://caffe2.ai/"><span style="font-family:Times New Roman;font-size:10.5pt;color:#0563C1;text-decoration: underline;">https://caffe2.ai/</span></a><span style="font-family:Times New Roman;font-size:10.5pt;">) to build their image detection and classification systems. For example, the official code of Faster RCNN is written by Caffe, our participants should transfer it to Caffe2.</span></p><p style="text-align:justify;margin-left:18pt;text-indent:-18pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">2.</span><span>&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; </span><span style="font-family:Times New Roman;font-size:10.5pt;">Participants must use Nvidia TX2 (</span><a href="https://developer.nvidia.com/embedded/buy/jetson-tx2"><span style="font-family:Times New Roman;font-size:10.5pt;color:#0563C1;text-decoration: underline;">https://developer.nvidia.com/embedded/buy/jetson-tx2</span></a><span style="font-family:Times New Roman;font-size:10.5pt;">) as their platform.</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span>&#xa0;</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:12pt;font-weight: bold;">Submission:</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">The participants must submit their caffe2 model with an output CSV file with the following format:</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span>&#xa0;</span></p><p style="margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">1 159 0.884664 119.976089 104.969680 446.638915 196.629038</span></p><p style="margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">3 134 0.956790 84.127186 80.494650 495.113390 265.696301</span></p><p style="margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">4 26 0.196648 140.979062 164.311968 355.728417 266.404466</span></p><p style="margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">5 134 0.835819 195.385994 108.760951 322.980318 239.285166</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">…</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">The meaning of each row is:</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">Image-name, Class-id, confidence, ymax, xmax, xmin, ymin. For more information, refer to </span><span style="font-family:Times New Roman;font-size:10.5pt;color:#0563C1;text-decoration: underline;">https://github.com/luyunghsiang/LPIRC/blob/master/client/source/client.py</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span>&#xa0;</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span>&#xa0;</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:12pt;font-weight: bold;">Evaluation:</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">Submissions will be evaluated based on the matrix as follows:</span></p><p style="text-align:center;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:12pt;font-weight: bold;color:#FF0000;">Score = </span></p><p style="text-align:justify;margin-left:36pt;text-indent:-18pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">1.</span><span>&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; </span><span style="font-family:Times New Roman;font-size:10.5pt;font-weight: bold;">mean average precision (mAP)</span></p><p style="text-align:justify;margin-left:28.45pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">The detection system can detect multiple objects in an image. We use mean average precision (mAP) as recognition accuracy. Specifically, participants’ detection systems classify different classes and recognize objects, draw the bounding box and report to the referee system. The referee system can be downloaded here: </span><a href="https://github.com/luyunghsiang/LPIRC"><span style="font-family:Times New Roman;font-size:10.5pt;color:#0563C1;text-decoration: underline;">https://github.com/luyunghsiang/LPIRC</span></a></p><p style="text-align:justify;margin-left:18pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span>&#xa0;</span></p><p style="text-align:justify;margin-left:18pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="width:278px;height:122px;margin-left:56px;position:absolute;margin-top: 0px;z-index:9999;"><img src="t0KxTe8L_files/Image1.png" width="278" height="122" border="0" /></span><span style="font-family:Times New Roman;font-size:10.5pt;"> </span></p><p style="text-align:justify;margin-left:18pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;" /><p style="text-align:justify;margin-left:18pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;" /><p style="text-align:justify;margin-left:18pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span>&#xa0;</span></p><p style="text-align:justify;margin-left:18pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span>&#xa0;</span></p><p style="text-align:justify;margin-left:18pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span>&#xa0;</span></p><p style="text-align:justify;margin-left:46.45pt;text-indent:-18pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">2.</span><span>&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; </span><span style="font-family:Times New Roman;font-size:10.5pt;font-weight: bold;">Energy consumption</span></p><p style="text-align:justify;margin-left:28.45pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:10.5pt;">Energy consumption part measures the participants’ hardware power usage without its own battery. Every participant will connect their TX2 to the powermeter offered by the organizer. This powermeter will provide AC/DC power supply and calculate the total energy consumption.</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span>&#xa0;</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:12pt;font-weight: bold;">Prize:</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span>&#xa0;</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span style="font-family:Times New Roman;font-size:12pt;font-weight: bold;">Timeline:</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span>&#xa0;</span></p><p style="text-align:justify;margin-left:0pt;margin-right:0pt;margin-top:0pt;margin-bottom:0pt;padding: 1pt 4pt;"><span>&#xa0;</span></p></div></body></html>